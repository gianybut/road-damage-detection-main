{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9268a5d1",
   "metadata": {},
   "source": [
    "# ğŸ›£ï¸ Road Damage Detection â€” YOLOv5 Training Notebook (Google Colab)\n",
    "\n",
    "**Thesis:** Road Damage Detection Mobile App for LGU Road Surveys Using YOLOv5\n",
    "\n",
    "This notebook trains a YOLOv5s model on the RDD2022 dataset **on Google Colab** with free GPU acceleration (NVIDIA T4/V100).\n",
    "\n",
    "## âœ¨ Advantages of Google Colab\n",
    "- **Free GPU:** NVIDIA T4 or V100 (saves money on cloud computing)\n",
    "- **No setup required:** Pre-installed Python, CUDA, PyTorch\n",
    "- **Easy collaboration:** Share notebook link with teammates\n",
    "- **Auto-saves:** Progress saved to Google Drive\n",
    "- **Integrated:** Direct access to Google Drive for data\n",
    "\n",
    "## ğŸ¯ Detects 4 Road Damage Types\n",
    "- **D00** â€” Longitudinal Crack\n",
    "- **D10** â€” Transverse Crack\n",
    "- **D20** â€” Alligator Crack\n",
    "- **D40** â€” Pothole\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9973a158",
   "metadata": {},
   "source": [
    "## Step 1: Connect to Google Drive & Check GPU\n",
    "\n",
    "First, we'll mount your Google Drive and verify GPU access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6163215a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "print(\"âœ… Google Drive mounted!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4a4d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU\n",
    "import torch\n",
    "import platform\n",
    "\n",
    "print(f\"Python: {platform.python_version()}\")\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    print(\"âš ï¸ No GPU found! Training will be slower.\")\n",
    "    device = \"cpu\"\n",
    "\n",
    "print(f\"\\nâœ… Device selected: {device.upper()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57b2926",
   "metadata": {},
   "source": [
    "## Step 2: Clone Repository & Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0073e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# Clone your repository (replace with your repo URL)\n",
    "repo_url = \"https://github.com/YOUR_USERNAME/road-damage-detection.git\"\n",
    "project_dir = \"/content/road-damage-detection\"\n",
    "\n",
    "if not os.path.exists(project_dir):\n",
    "    print(f\"ğŸ“¥ Cloning repository...\")\n",
    "    subprocess.run([\"git\", \"clone\", repo_url, project_dir], check=True)\n",
    "    print(\"âœ… Repository cloned!\")\n",
    "else:\n",
    "    print(f\"âœ… Repository already exists at {project_dir}\")\n",
    "\n",
    "os.chdir(project_dir)\n",
    "print(f\"\\nğŸ“ Working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8b28cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "print(\"ğŸ“¦ Installing dependencies...\")\n",
    "\n",
    "# Core packages\n",
    "subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\",\n",
    "                 \"ultralytics\", \"opencv-python-headless\", \n",
    "                 \"Pillow\", \"pyyaml\", \"torch-class-imbalance\"], check=False)\n",
    "\n",
    "print(\"âœ… Dependencies installed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806f77cd",
   "metadata": {},
   "source": [
    "## Step 3: Prepare Dataset\n",
    "\n",
    "### Option A: Download from Kaggle (Recommended)\n",
    "1. Get Kaggle API key: https://www.kaggle.com/settings/account\n",
    "2. Upload `kaggle.json` to Colab\n",
    "3. Run the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca65216b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option A: Download from Kaggle\n",
    "try:\n",
    "    from google.colab import files\n",
    "    print(\"ğŸ“¤ Upload your kaggle.json (from https://www.kaggle.com/settings/account)\")\n",
    "    uploaded = files.upload()\n",
    "    \n",
    "    # Setup Kaggle\n",
    "    subprocess.run([\"mkdir\", \"-p\", \"/root/.kaggle\"], check=True)\n",
    "    subprocess.run([\"cp\", \"kaggle.json\", \"/root/.kaggle/\"], check=True)\n",
    "    subprocess.run([\"chmod\", \"600\", \"/root/.kaggle/kaggle.json\"], check=True)\n",
    "    \n",
    "    # Download dataset\n",
    "    print(\"\\nğŸ“¥ Downloading RDD2022 dataset from Kaggle...\")\n",
    "    subprocess.run([\"pip\", \"install\", \"-q\", \"kaggle\"], check=True)\n",
    "    subprocess.run([\n",
    "        \"kaggle\", \"datasets\", \"download\", \n",
    "        \"-d\", \"chitholian/road-damage-detection-rdd2022\",\n",
    "        \"-p\", \"backend/data\", \"--unzip\"\n",
    "    ], check=True)\n",
    "    \n",
    "    print(\"âœ… Dataset downloaded!\")\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ Kaggle download skipped: {e}\")\n",
    "    print(\"\\nUsing Option B instead...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556dbf72",
   "metadata": {},
   "source": [
    "### Option B: Use Google Drive\n",
    "1. Upload dataset to `My Drive/road-damage-detection/`\n",
    "2. Run the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c27545d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option B: Copy from Google Drive\n",
    "drive_dataset_path = \"/content/drive/MyDrive/road-damage-detection/data\"\n",
    "local_data_path = \"backend/data\"\n",
    "\n",
    "if os.path.exists(drive_dataset_path):\n",
    "    print(f\"ğŸ“‹ Found dataset in Google Drive at: {drive_dataset_path}\")\n",
    "    print(f\"ğŸ“¥ Copying to: {local_data_path}\")\n",
    "    \n",
    "    os.makedirs(local_data_path, exist_ok=True)\n",
    "    \n",
    "    # Copy images\n",
    "    if os.path.exists(os.path.join(drive_dataset_path, \"images\")):\n",
    "        subprocess.run([\n",
    "            \"cp\", \"-r\", \n",
    "            os.path.join(drive_dataset_path, \"images\"),\n",
    "            local_data_path\n",
    "        ], check=True)\n",
    "        print(\"âœ… Images copied\")\n",
    "    \n",
    "    # Copy labels\n",
    "    if os.path.exists(os.path.join(drive_dataset_path, \"labels\")):\n",
    "        subprocess.run([\n",
    "            \"cp\", \"-r\",\n",
    "            os.path.join(drive_dataset_path, \"labels\"),\n",
    "            local_data_path\n",
    "        ], check=True)\n",
    "        print(\"âœ… Labels copied\")\n",
    "else:\n",
    "    print(f\"âš ï¸ Dataset not found at {drive_dataset_path}\")\n",
    "    print(\"\\nInstructions:\")\n",
    "    print(\"1. Create folder: My Drive â†’ New Folder â†’ 'road-damage-detection'\")\n",
    "    print(\"2. Upload dataset inside this folder\")\n",
    "    print(\"3. Re-run this cell\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeba0e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup data structure\n",
    "print(\"ğŸ“ Setting up data structure...\")\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, 'backend')\n",
    "\n",
    "os.chdir(\"backend\")\n",
    "from download_dataset import setup_directory_structure, create_data_yaml\n",
    "\n",
    "setup_directory_structure()\n",
    "create_data_yaml()\n",
    "\n",
    "print(\"âœ… Data structure ready!\")\n",
    "\n",
    "# Check dataset\n",
    "data_dir = \"data\"\n",
    "train_images = os.path.join(data_dir, \"images\", \"train\")\n",
    "train_labels = os.path.join(data_dir, \"labels\", \"train\")\n",
    "\n",
    "if os.path.exists(train_images):\n",
    "    num_images = len(os.listdir(train_images))\n",
    "    print(f\"\\nğŸ“Š Training images: {num_images}\")\n",
    "if os.path.exists(train_labels):\n",
    "    num_labels = len(os.listdir(train_labels))\n",
    "    print(f\"ğŸ“Š Training labels: {num_labels}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f56a49a",
   "metadata": {},
   "source": [
    "## Step 4: Train YOLOv5 Model\n",
    "\n",
    "The model will train on the RDD2022 dataset. This takes ~2-4 hours with GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a53abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import YOLOv5\n",
    "from ultralytics import YOLO\n",
    "import torch\n",
    "\n",
    "print(\"ğŸš€ Starting YOLOv5 Training...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Create model\n",
    "model = YOLO('yolov5s.pt')  # Use yolov5s (smaller, faster)\n",
    "\n",
    "# Training configuration\n",
    "results = model.train(\n",
    "    data='data/data.yaml',\n",
    "    epochs=50,                    # Adjust based on GPU memory\n",
    "    imgsz=640,\n",
    "    batch=16,                    # Reduce if OOM: use 8 or 4\n",
    "    patience=10,                 # Early stopping\n",
    "    device=0 if torch.cuda.is_available() else 'cpu',\n",
    "    workers=4,\n",
    "    cache='disk',               # Cache to disk (saves RAM)\n",
    "    save=True,                  # Save checkpoints\n",
    "    save_period=5,              # Save every 5 epochs\n",
    "    verbose=True,\n",
    "    amp=True,                   # Automatic mixed precision\n",
    "    augment=True,               # Data augmentation\n",
    "    hsv_h=0.015,                # HSV-color augmentation\n",
    "    hsv_s=0.7,\n",
    "    hsv_v=0.4,\n",
    "    degrees=10,\n",
    "    translate=0.1,\n",
    "    scale=0.5,\n",
    "    dropout=0.0\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"âœ… Training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bc6487",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate the model\n",
    "print(\"ğŸ“Š Validating model...\")\n",
    "val_results = model.val()\n",
    "print(\"âœ… Validation completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98ea450",
   "metadata": {},
   "source": [
    "## Step 5: Download Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f14500c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save best model to Google Drive for backup\n",
    "import shutil\n",
    "\n",
    "trained_model = \"runs/detect/train/weights/best.pt\"\n",
    "models_dir = \"models\"\n",
    "\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "\n",
    "if os.path.exists(trained_model):\n",
    "    shutil.copy2(trained_model, os.path.join(models_dir, \"best.pt\"))\n",
    "    print(f\"âœ… Model saved to: {os.path.join(models_dir, 'best.pt')}\")\n",
    "    \n",
    "    # Also save to Google Drive\n",
    "    drive_save_path = \"/content/drive/MyDrive/road-damage-detection/best.pt\"\n",
    "    os.makedirs(os.path.dirname(drive_save_path), exist_ok=True)\n",
    "    shutil.copy2(trained_model, drive_save_path)\n",
    "    print(f\"âœ… Also saved to Google Drive: {drive_save_path}\")\n",
    "else:\n",
    "    print(f\"âš ï¸ Trained model not found at {trained_model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f8afd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download model files\n",
    "from google.colab import files\n",
    "\n",
    "print(\"ğŸ“¥ Downloading model files...\")\n",
    "files.download(os.path.join(models_dir, \"best.pt\"))\n",
    "print(\"âœ… Download started!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f31bef3",
   "metadata": {},
   "source": [
    "## Step 6: Test the Model\n",
    "\n",
    "Run inference on a sample image to verify the model works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934406d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on a sample image\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "\n",
    "# Get first test image\n",
    "test_images_dir = \"data/images/val\"\n",
    "if os.path.exists(test_images_dir):\n",
    "    test_images = list(Path(test_images_dir).glob(\"*.jpg\")) + list(Path(test_images_dir).glob(\"*.png\"))\n",
    "    \n",
    "    if test_images:\n",
    "        test_image = str(test_images[0])\n",
    "        print(f\"ğŸ§ª Testing on: {test_image}\")\n",
    "        \n",
    "        # Run inference\n",
    "        results = model.predict(test_image, conf=0.25, imgsz=640)\n",
    "        \n",
    "        # Display results\n",
    "        import matplotlib.pyplot as plt\n",
    "        from PIL import Image\n",
    "        \n",
    "        result_image = results[0].plot()\n",
    "        result_image = cv2.cvtColor(result_image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        plt.figure(figsize=(12, 8))\n",
    "        plt.imshow(result_image)\n",
    "        plt.axis('off')\n",
    "        plt.title('Road Damage Detection Results')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"\\nâœ… Test inference completed!\")\n",
    "    else:\n",
    "        print(\"âš ï¸ No test images found in val/ directory\")\n",
    "else:\n",
    "    print(f\"âš ï¸ Test images directory not found: {test_images_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392cecbc",
   "metadata": {},
   "source": [
    "## Step 7: Training Summary\n",
    "\n",
    "Display training metrics and results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7e5b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display training results\n",
    "train_dir = \"runs/detect/train\"\n",
    "if os.path.exists(train_dir):\n",
    "    print(\"ğŸ“Š Training Results:\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # List generated files\n",
    "    for root, dirs, files in os.walk(train_dir):\n",
    "        level = root.replace(train_dir, '').count(os.sep)\n",
    "        indent = ' ' * 2 * level\n",
    "        print(f'{indent}ğŸ“ {os.path.basename(root)}/')\n",
    "        subindent = ' ' * 2 * (level + 1)\n",
    "        for file in files[:5]:  # Limit to 5 files per directory\n",
    "            print(f'{subindent}ğŸ“„ {file}')\n",
    "        if len(files) > 5:\n",
    "            print(f'{subindent}... and {len(files) - 5} more files')\n",
    "else:\n",
    "    print(\"âš ï¸ Training directory not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5880271",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. âœ… Download `best.pt` from this notebook\n",
    "2. ğŸ“± Copy to mobile app: `mobile/models/best.pt`\n",
    "3. ğŸš€ Deploy to your Flask backend\n",
    "4. ğŸ“Š Monitor detection accuracy in production\n",
    "\n",
    "---\n",
    "**Created with â¤ï¸ for road damage detection in LGU road surveys**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
